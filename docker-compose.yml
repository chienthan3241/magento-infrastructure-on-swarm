################ SCALEABLE MAGENTO INFRASTRUCTURE ###################
# author: s.hueltenschmidt@kernel-consulting.de
# created: 2018-04-10
# runs on docker swarm mode 17.12+
# needs at least 3 nodes, stick to odd numbers of nodes for quorum decisions
#
# ALL VOLUMES AND CONFIG FILES NEED TO BE AVAILABLE ON ALL NODES, THIS IS NOT DONE HERE
#
# notes:
# docker swarm mode is not yet able to limit a service to 1 instance per node
# the workaround for this is to set a service mode to "global" (1 instance per each node) and limit its deployment by placement constraints
# this is used here for services that shloud only run once, because the use a writeable volume, e.g. galera.
#
# galera specific startup instructions:
# lets assume 3 node with the names node1, node2 and node3
# make sure all node have their dbnode and dbseed label set to 0 with "docker node update --label-add dbnode=0 <node1, node2, node3>" and "docker node update --label-add dbseed=0 <node1, node2, node3>" (of course one command for each node)
# after deployment with "docker stack deploy -c docker-compose.yml" <stackname>
# you should at first start a "seed" node with "docker node update --label-add dbseed=1 node1" (it does not matte which node, choose the one you guess has the most current/intact data)
# verify you node is up with "docker ps" on the cooresponding node
# verify docker has set the vip and its dns entry with: "docker exec <seedcontainerid> getent seed"
# it should give you an ip. Otherwise you can enforce it with "docker service update --force <stackname>_seed" but it should only be a temporary fix. Fix your docker installation, i had trouble with paravirtualized linux xen domU as docker host on qubes os. hvm xen domU worked ok.
# after the seed node is up, start two dbnode on _different_ nodes than the seed node by "docker node update --label-add dbnode=1 <node2, node3>" (again 1 command for each node, the nodes that are _not_ the seed node)
# verify the vip and dns is up, it may take a while: "docker exec <seedcontainerid> getent dbnode"
# when the vip is up check one of the nodes for a completed resync: "docker ps" followed by "docker logs <nodecontainerid>"
# when the dbnodes are synced, stop the seed node by: "docker node update --label-add dbseed=0 node1" (or whatever node you have chosen at start).
# after the shutdown, start a normal dbnode on the seed node by  "docker node update --label-add dbnode=1 node1" (or whatever node you have chosen at start)(or whatever node you have chosen at start)(or whatever node you have chosen at start)(or whatever node you have chosen at start).
# check if it syncs correctly.
# galera is now working on all 3(5,7) nodes.
# repeat this for each startup, whenever you took down galera. Spinning up and down instances is no problem, as long as at least a mayority of nodes stays up.

# spinning up the backend nginx should be done after all of the other services are up by: "docker service scale <stackname>_magento=3"


version: '3.5'

services:

  dbseedgalera:
    image: registry.devgmt.com/gmt/mariadb-galera-swarm:latest
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      replicas: 1
      placement:
        constraints:
#NEVER run in parallel with a db node, allow fast switching by setting node.labels.dbnodegalera=1
          - node.labels.dbnodegalera==0  
          - node.labels.dbseedgalera==1
    networks:
      - backbone
    command: seed
    volumes:
      - mysql-data:/var/lib/mysql
    environment:
      - XTRABACKUP_PASSWORD_FILE=/run/secrets/xtrabackup_password
      - MYSQL_USER=magento2
      - MYSQL_PASSWORD_FILE=/run/secrets/mysql_password
      - MYSQL_DATABASE=germantom
      - MYSQL_ROOT_PASSWORD_FILE=/run/secrets/mysql_root_password
#      - NODE_ADDRESS=^10.0.0.*
    secrets:
      - xtrabackup_password
      - mysql_password
      - mysql_root_password
    logging:
        driver: journald
        options:
            tag: dbseedgalera

  dbnodegalera:
    image: registry.devgmt.com/gmt/mariadb-galera-swarm:latest
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    networks:
      - backbone
    command: node dbseedgalera,dbnodegalera
    volumes:
      - mysql-data:/var/lib/mysql
    deploy:
#start 1 db node on every swarm node, but only on those who carry the dbnode label
      mode: global
      placement:
        constraints:
          - node.labels.dbnodegalera==1
      update_config:
        delay: 60s
        order: stop-first
        monitor: 60s
    environment:
      - XTRABACKUP_PASSWORD_FILE=/run/secrets/xtrabackup_password
#      - NODE_ADDRESS=^10.0.0.*
#      - HEALTHY_WHILE_BOOTING=1
#      - GCOMM_MINIMUM=1
    secrets:
      - xtrabackup_password
      - mysql_password
      - mysql_root_password
    logging:
        driver: journald
        options:
            tag: dbnodegalera

  cacheredismaster:
    image: redis:alpine
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.cacheredismaster==1
    command: redis-server /redis.conf
    volumes:
      - cache-redis-master-data:/data
    configs:
      - source: cache-redis-master-config   
        target: /redis.conf
        mode: 0444
    networks:
      - backbone
    logging:
        driver: journald
        options:
            tag: cacheredismaster

  cacheredisslave:
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    image: redis:alpine
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.labels.cacheredisslave==1
    command: redis-server /redis.conf
    volumes:
      - cache-redis-slave-data:/data
    configs:
      - source: cache-redis-slave-config
        target: /redis.conf
        mode: 0444
    networks:
      - backbone
    logging:
        driver: journald
        options:
            tag: cacheredisslave

  sessionredismaster:
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    image: redis:alpine
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.sessionredismaster==1
    command: redis-server /redis.conf
    volumes:
      - session-redis-master-data:/data
    configs:
      - source: session-redis-master-config
        target: /redis.conf
        mode: 0444
    networks:
      - backbone
    logging:
        driver: journald
        options:
            tag: sessionredismaster

  sessionredisslave:
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    image: redis:alpine
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.labels.sessionredisslave==1
    command: redis-server /redis.conf
    volumes:
      - session-redis-slave-data:/data
    configs:
      - source: session-redis-slave-config
        target: /redis.conf
        mode: 0444
    networks:
      - backbone
    logging:
        driver: journald
        options:
            tag: sessionredisslave

  frontendnginx:
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    image: nginx:latest
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.frontendnginx==1
    command: sh -c "exec nginx -g 'daemon off;'"
    networks:
      - backbone
    secrets:
      - source: ${FRONTEND_CERT}.crt.5
        target: /etc/ssl/certs/site.crt
      - source: ${FRONTEND_CERT}.key.5
        target: /etc/ssl/certs/site.key
    configs:
      - source: frontend-nginx-config.5
        target: /etc/nginx/nginx.conf
      - source: frontend-nginx-default.5
        target: /etc/nginx/conf.d/default.conf
      - source: frontend-nginx-pfs.7
        target: /etc/nginx/conf.d/perfect-forward-secrecy.conf
      - source: frontend-nginx-dh
        target: /etc/nginx/dh4096.pem
#        uid: '103'
#        gid: '103'
        mode: 0440
    ports:
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 80
        published: 80
        protocol: tcp
        mode: host
    logging:
        driver: journald
        options:
            tag: frontendnginx

  backendnginx:
    image: nginx:latest
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.labels.backendnginx==1
    command: sh -c "exec nginx -g 'daemon off;'"
    networks:
      - backbone
    configs:
      - source: backend-nginx-config
        target: /etc/nginx/nginx.conf
#        uid: '103'
#        gid: '103'
        mode: 0440
      - source: backend-nginx-default.3
        target: /etc/nginx/conf.d/default.conf
#        uid: '103'
#        gid: '103'
        mode: 0440
#    environment:
#env variables not working in nginx config files
#      - APP_MODE = "production"
#      - PHP_HOST = php
#      - PHP_PORT = 9000
    volumes: &appvolumes
      - appdata:/var/www/html
      - aiodata:/var/www/aio2       
      - composer:/var/www/.composer
#      - ~/.composer:/var/www/.composer
    logging:
        driver: journald
        options:
            tag: backendnginx
#    ports:
#      - "8080:80"

  applicationphp:
      image: registry.devgmt.com/gmt/php-swarm:2018-06-22
      labels:
        - "com.germantom.deployment=${DEPLOYMENT}"
      deploy:
          replicas: 1
          placement:
            constraints:
              - node.labels.applicationphp==1
      volumes: *appvolumes
      networks:
          - backbone
      tty: true
      logging:
          driver: journald
          options:
              tag: applicationphp
      # Pass variable from environment through to container
      environment:
          POSTFIX_HOSTNAME:

  applicationcron:
     image: registry.devgmt.com/gmt/cron-swarm:2018-06-22
     labels:
       - "com.germantom.deployment=${DEPLOYMENT}"
     deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.applicationcron==1
     volumes: *appvolumes
     networks:
       - backbone
     configs:
       - source: application-cron-config.5
         target: /usr/local/etc/crontab

     tty: true
     logging:
        driver: journald
        options:
            tag: applicationcron
 
  fullpagecachevarnish:
     image: registry.devgmt.com/gmt/varnish-swarm:latest
     labels:
       - "com.germantom.deployment=${DEPLOYMENT}"
     deploy:
      replicas: 3
      placement:
        constraints:
          - node.labels.fullpagecachevarnish==1
     networks:
       - backbone
#     environment:
#       - VARNISH_BACKEND_PORT=80
#       - VARNISH_BACKEND_IP=backendnginx
#       - VARNISH_PORT=8000     
     configs:
       - source: fullpagecache-varnish-config.3
         target: /varnish/config.vcl
         mode: 0740
#         uid: root
#         gid: varnish
#     ports:
#       - "6082:6082"
#       - "80:80"
     tty: true
     logging:
        driver: journald
        options:
            tag: fullpagecachevarnish

  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      replicas: 0    
    networks:
       - backbone
    environment:
      - PMA_ARBITRARY=1
    ports:
      - "8123:80"
    logging:
        driver: journald
        options:
            tag: phpmyadmin
          
  rsyncmaster:
    image: registry.devgmt.com/gmt/rsyncer-swarm:2018-06-21
    command: "/bin/bash -c \"trap : TERM INT; /start.sh master\""
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      mode: global
      placement:
        constraints:
#sync wherever the app is
          - node.labels.applicationphp==1
    volumes: &syncvolumes
      - appdata:/opt/syncfiles/appdata
      - aiodata:/opt/syncfiles/aio2
      - composer:/opt/syncfiles/composer
    networks:
      - backbone
    secrets:
      - source: rsyncer.key
        target: /root/.ssh/rsyncer.key
        mode: 0400
      - source: rsyncer.key.pub                
        target: /root/.ssh/authorized_keys
        mode: 0400
    logging:
        driver: journald
        options:
            tag: volumesyncrsyncer
          
  rsyncslave:
    image: registry.devgmt.com/gmt/rsyncer-swarm:2018-06-21
    command: "/bin/bash -c \"trap : TERM INT; /start.sh slave\""
    labels:
      - "com.germantom.deployment=${DEPLOYMENT}"
    deploy:
      mode: global
      placement:
        constraints:
#sync wherever the app is not
          - node.labels.applicationphp!=1
    volumes: *syncvolumes
    networks:
      - backbone
    secrets:
      - source: rsyncer.key
        target: /root/.ssh/rsyncer.key
        mode: 0400
      - source: rsyncer.key.pub                
        target: /root/.ssh/authorized_keys
        mode: 0400
    logging:
        driver: journald
        options:
            tag: volumesyncrsyncer

volumes:
  mysql-data:
    driver: local
  cache-redis-master-data:
    driver: local
  cache-redis-slave-data:
    driver: local
  session-redis-master-data:
    driver: local
  session-redis-slave-data:
    driver: local
  appdata:
    driver: local
  aiodata:
    driver: local
  composer:
    driver: local

networks:
  backbone:
    driver: overlay
    attachable: true
  
  frontend:
    driver: overlay
    attachable: false


secrets:
  xtrabackup_password:
    file: .secrets/xtrabackup_password
  mysql_password:
    file: .secrets/mysql_password
  mysql_root_password:
    file: .secrets/mysql_root_password
  # BEGIN: Always bump all four numbers in sync!
  site.crt.5:
    file: ./frontend-nginx-config/certs/site.crt
  site.key.5:
    file: ./frontend-nginx-config/certs/site.key
  staging.crt.5:
    file: ./frontend-nginx-config/certs/staging.crt
  staging.key.5:
    file: ./frontend-nginx-config/certs/staging.key
  # END: Always bump all four numbers in sync!
  rsyncer.key:
    file: ./.secrets/rsyncer.key
  rsyncer.key.pub:
    file: ./.secrets/rsyncer.key.pub

configs:
  cache-redis-master-config:
    file: ./session-redis-master-config/redis.conf
  cache-redis-slave-config:
    file: ./session-redis-slave-config/redis.conf
  session-redis-master-config:
    file: ./session-redis-master-config/redis.conf
  session-redis-slave-config:
    file: ./session-redis-slave-config/redis.conf  
  frontend-nginx-config.5:
    file: ./frontend-nginx-config/nginx.conf
  frontend-nginx-default.5:
    file: ./frontend-nginx-config/site.conf
  frontend-nginx-pfs.7:
    file: ./frontend-nginx-config/perfect-forward-secrecy.conf
  frontend-nginx-dh:
    file: ./frontend-nginx-config/dh4096.pem
  backend-nginx-config:
    file: ./backend-nginx-config/nginx.conf
  backend-nginx-default.3:
    file: ./backend-nginx-config/default.conf
  fullpagecache-varnish-config.3:
    file: ./fullpagecache-varnish-config/varnish.vcl
  application-cron-config.5:
    file: ./application-cron-config/crontab

